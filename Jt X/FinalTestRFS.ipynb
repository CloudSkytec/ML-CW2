{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d43449-4065-402b-bb01-57320a60158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7907b2c5-f9e5-47df-abfd-7e5ddfdad354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Load Data\n",
    "file_path = \"./TrainDataset2024.xls\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "df.replace(999, np.nan, inplace=True)\n",
    "\n",
    "# Drop pCR (classification target)\n",
    "df.drop(columns=\"pCR (outcome)\", inplace=True)\n",
    "\n",
    "# Ensure no missing in RFS\n",
    "df = df[df['RelapseFreeSurvival (outcome)'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71752a4f-a7a3-498c-a616-2d8d4be508e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Imputation\n",
    "categorical_features = ['ER', 'PgR', 'HER2', 'TrippleNegative', 'ChemoGrade', \n",
    "                        'Proliferation', 'HistologyType', 'LNStatus', 'TumourStage', 'Gene']\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_features] = imputer_cat.fit_transform(df[categorical_features])\n",
    "\n",
    "# Numerical Imputation\n",
    "numerical_features = [col for col in df.columns if col not in categorical_features + ['ID', 'RelapseFreeSurvival (outcome)']]\n",
    "imputer_num = KNNImputer(n_neighbors=5)\n",
    "df[numerical_features] = imputer_num.fit_transform(df[numerical_features])\n",
    "\n",
    "# Outlier Handling\n",
    "for col in numerical_features:\n",
    "    q1 = df[col].quantile(0.20)\n",
    "    q3 = df[col].quantile(0.80)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "\n",
    "# Data Standardization\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e0c618-fca4-48bb-ad0f-fccd91f2360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size after custom oversampling: (480, 118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\MLE\\lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Splitting Data\n",
    "X = df.drop(columns=['ID', 'RelapseFreeSurvival (outcome)'])\n",
    "y = df['RelapseFreeSurvival (outcome)']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 3: Custom Oversampling for Regression\n",
    "def oversample_with_noise(X, y, ratio=0.5, noise_level=0.01):\n",
    "    from sklearn.utils import resample\n",
    "    minority_idx = np.where(y < np.percentile(y, 25))[0]\n",
    "    X_minority = X[minority_idx]\n",
    "    y_minority = y[minority_idx]\n",
    "    X_resampled = resample(X_minority, replace=True, n_samples=int(len(y) * ratio), random_state=42)\n",
    "    y_resampled = resample(y_minority, replace=True, n_samples=int(len(y) * ratio), random_state=42)\n",
    "    X_resampled += noise_level * np.random.randn(*X_resampled.shape)\n",
    "    X_augmented = np.vstack([X, X_resampled])\n",
    "    y_augmented = np.hstack([y, y_resampled])\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "X_train_resampled, y_train_resampled = oversample_with_noise(X_train.values, y_train.values)\n",
    "print(\"Training set size after custom oversampling:\", X_train_resampled.shape)\n",
    "\n",
    "# Step 4: Dimensionality Reduction\n",
    "pca = PCA(n_components=18)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "X_val_pca = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b77625e1-e505-4623-9e7c-0a3a99279626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Models and Optimized Parameter Grids\n",
    "models_and_grids = {\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42),\n",
    "        \"param_grid\": {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=42),\n",
    "        \"param_grid\": {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 5],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'loss': ['huber']\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "        \"param_grid\": {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 5],\n",
    "            'reg_alpha': [0, 0.1, 1],\n",
    "            'reg_lambda': [1, 10, 100]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43932029-a6ab-48aa-a05a-b6327a9cd00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best parameters for RandomForest: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Training GradientBoosting...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters for GradientBoosting: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}\n",
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train and Evaluate Models\n",
    "results = {}\n",
    "for model_name, config in models_and_grids.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=config[\"model\"],\n",
    "        param_grid=config[\"param_grid\"],\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    grid_search.fit(X_train_pca, y_train_resampled)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_pred = best_model.predict(X_val_pca)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fe40dab-0de7-4792-9f3a-349fc9d552bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "\n",
      "RandomForest:\n",
      "MAE: 22.5453\n",
      "MSE: 922.0304\n",
      "RMSE: 30.3650\n",
      "R2: -0.1553\n",
      "\n",
      "GradientBoosting:\n",
      "MAE: 25.6579\n",
      "MSE: 1069.7854\n",
      "RMSE: 32.7076\n",
      "R2: -0.3405\n",
      "\n",
      "XGBoost:\n",
      "MAE: 24.5146\n",
      "MSE: 1015.2533\n",
      "RMSE: 31.8630\n",
      "R2: -0.2722\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Print Results\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c5e46-1bef-4b5a-9835-e313fd21e98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
