{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Loading Data\n",
    "file_path = \"./TrainDataset2024.xls\"\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of missing value in Gene: 0.28205128205128205\n",
      "Ratio of Class 1: 0.21265822784810126\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# replace 999 with NaN\n",
    "df.replace(999, np.nan, inplace=True)\n",
    "\n",
    "# Imputation of Gene\n",
    "print(f\"Ratio of missing value in Gene: {df['Gene'].isnull().sum() / df['Gene'].count()}\")\n",
    "df['Gene'] = df['Gene'].fillna(-1)\n",
    "\n",
    "# Make sure no missing in pCR\n",
    "df = df[df['pCR (outcome)'].isin([0, 1])]\n",
    "\n",
    "# Check imbalance \n",
    "print(f\"Ratio of Class 1: {(df['pCR (outcome)']==1).sum() / df['pCR (outcome)'].count()}\")\n",
    "\n",
    "# Drop RFS\n",
    "df.drop(columns=\"RelapseFreeSurvival (outcome)\",inplace=True)\n",
    "\n",
    "# Categorical imputation\n",
    "categorical_features = ['ER', 'PgR','HER2', 'TrippleNegative', 'ChemoGrade','Proliferation','HistologyType','LNStatus','TumourStage', 'Gene']\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_features] = imputer_cat.fit_transform(df[categorical_features])\n",
    "\n",
    "# Numerical Imputation\n",
    "numerical_features = [col for col in df.columns if col not in categorical_features + ['ID', 'pCR (outcome)']]\n",
    "imputer_num = KNNImputer(n_neighbors=5)\n",
    "df[numerical_features] = imputer_num.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "for col in numerical_features:\n",
    "    q1 = df[col].quantile(0.20)\n",
    "    q3 = df[col].quantile(0.80)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    \n",
    "# Data Standardization\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = df.drop(columns=['ID', 'pCR (outcome)']) \n",
    "y = df['pCR (outcome)']\n",
    "\n",
    "# 8:2 splitting with stratified strategy\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: [249 249]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22519\\AppData\\Local\\Temp\\ipykernel_15956\\1371694761.py:6: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  print(\"Class distribution after SMOTE:\", np.bincount(y_train_resampled))\n"
     ]
    }
   ],
   "source": [
    "# Oversampling(SMOTE)\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "smote = SMOTENC(categorical_features = categorical_features, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class distribution after SMOTE:\", np.bincount(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Performance evaluation\n",
    "def evaluate_model(model,y_val,y_pred):\n",
    "    print(model)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    # Metrics\n",
    "    b_accuracy = balanced_accuracy_score(y_val,y_pred)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    # Display Metrics\n",
    "    print(f\"Blanced Accuracy: {b_accuracy:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying PCA to deduct demensions\n",
    "pca = PCA(n_components = 18)\n",
    "X_train_pca,X_val_pca = pca.fit_transform(X_train_resampled),pca.transform(X_val)\n",
    "X_train_pca,X_val_pca = pd.DataFrame(X_train_pca),pd.DataFrame(X_val_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.2, max_iter=500, random_state=42, solver='liblinear')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.76      0.82        62\n",
      "         1.0       0.42      0.65      0.51        17\n",
      "\n",
      "    accuracy                           0.73        79\n",
      "   macro avg       0.65      0.70      0.66        79\n",
      "weighted avg       0.79      0.73      0.75        79\n",
      "\n",
      "Blanced Accuracy: 0.7026\n",
      "Accuracy: 0.7342\n",
      "Precision: 0.4231\n",
      "Recall: 0.6471\n",
      "F1-Score: 0.5116\n",
      "ROC-AUC: 0.7026\n"
     ]
    }
   ],
   "source": [
    "# Model 1: LogisticRegression\n",
    "lr = LogisticRegression(C=1.2,max_iter=500,solver='liblinear',random_state=42)\n",
    "lr.fit(X_train_pca, y_train_resampled)\n",
    "y_probs = lr.predict_proba(X_val_pca)[:, 1]\n",
    "y_pred = (y_probs >= 0.52).astype(int)\n",
    "evaluate_model(lr,y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=75, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.77      0.82        62\n",
      "         1.0       0.42      0.59      0.49        17\n",
      "\n",
      "    accuracy                           0.73        79\n",
      "   macro avg       0.64      0.68      0.65        79\n",
      "weighted avg       0.77      0.73      0.75        79\n",
      "\n",
      "Blanced Accuracy: 0.6812\n",
      "Accuracy: 0.7342\n",
      "Precision: 0.4167\n",
      "Recall: 0.5882\n",
      "F1-Score: 0.4878\n",
      "ROC-AUC: 0.6812\n"
     ]
    }
   ],
   "source": [
    "# Model 2: RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=75,random_state=42)\n",
    "rf.fit(X_train_pca, y_train_resampled)\n",
    "y_probs = rf.predict_proba(X_val_pca)[:, 1]\n",
    "y_pred = (y_probs >= 0.48).astype(int)\n",
    "evaluate_model(rf,y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.47, n_estimators=170,\n",
      "                   random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.74      0.82        62\n",
      "         1.0       0.45      0.76      0.57        17\n",
      "\n",
      "    accuracy                           0.75        79\n",
      "   macro avg       0.68      0.75      0.69        79\n",
      "weighted avg       0.82      0.75      0.77        79\n",
      "\n",
      "Blanced Accuracy: 0.7533\n",
      "Accuracy: 0.7468\n",
      "Precision: 0.4483\n",
      "Recall: 0.7647\n",
      "F1-Score: 0.5652\n",
      "ROC-AUC: 0.7533\n"
     ]
    }
   ],
   "source": [
    "# Model 3: AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(algorithm='SAMME',learning_rate= 0.47,n_estimators=170, random_state=42)\n",
    "clf.fit(X_train_pca, y_train_resampled)\n",
    "y_probs = clf.predict_proba(X_val_pca)[:, 1]\n",
    "y_pred = (y_probs >= 0.51).astype(int)\n",
    "evaluate_model(clf,y_val,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
